{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\"\"\"Atom optimization algorithm is a combination of two other extensions a \n",
    "stochastic gradient descent notably Ada grad and armis prop and is a very efficient stochastic \n",
    "optimization method in updating the weights of our network.\"\"\"\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x6367391d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_pts = 500\n",
    "np.random.seed(0)\n",
    "Xa = np.array([np.random.normal(13, 2, n_pts),\n",
    "               np.random.normal(12, 2, n_pts)]).T\n",
    "Xb = np.array([np.random.normal(8, 2, n_pts),\n",
    "               np.random.normal(6, 2, n_pts)]).T\n",
    " \n",
    "X = np.vstack((Xa, Xb))\n",
    "y = np.matrix(np.append(np.zeros(n_pts), np.ones(n_pts))).T\n",
    " \n",
    "plt.scatter(X[:n_pts,0], X[:n_pts,1])\n",
    "plt.scatter(X[n_pts:,0], X[n_pts:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/elliotbriant/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 0s 145us/step - loss: 1.4228 - accuracy: 0.5550\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6248 - accuracy: 0.6120\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.4457 - accuracy: 0.8290\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3837 - accuracy: 0.8950\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.3406 - accuracy: 0.9050\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.3076 - accuracy: 0.9270\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.2883 - accuracy: 0.9330\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.2608 - accuracy: 0.9390\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2344 - accuracy: 0.9580\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2188 - accuracy: 0.9630\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2036 - accuracy: 0.9580\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1922 - accuracy: 0.9600\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1803 - accuracy: 0.9670\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.1711 - accuracy: 0.9680\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.1656 - accuracy: 0.9650\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.1574 - accuracy: 0.9670\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1496 - accuracy: 0.9690\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.1445 - accuracy: 0.9670\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1387 - accuracy: 0.9760\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1332 - accuracy: 0.9740\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1310 - accuracy: 0.9740\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1262 - accuracy: 0.9750\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1275 - accuracy: 0.9720\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1241 - accuracy: 0.9720\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1162 - accuracy: 0.9730\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1117 - accuracy: 0.9790\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1101 - accuracy: 0.9750\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1092 - accuracy: 0.9780\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1077 - accuracy: 0.9750\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 1.00 - 0s 30us/step - loss: 0.1029 - accuracy: 0.9780\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1019 - accuracy: 0.9770\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1015 - accuracy: 0.9770\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0998 - accuracy: 0.9750\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0964 - accuracy: 0.9780\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0944 - accuracy: 0.9770\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0942 - accuracy: 0.9780\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0928 - accuracy: 0.9770\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0918 - accuracy: 0.9780\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0942 - accuracy: 0.9760\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0923 - accuracy: 0.9750\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1021 - accuracy: 0.9670\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0897 - accuracy: 0.9760\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0869 - accuracy: 0.9770\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0917 - accuracy: 0.9730\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0936 - accuracy: 0.9690\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0987 - accuracy: 0.9660\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0846 - accuracy: 0.9740\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0824 - accuracy: 0.9780\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0813 - accuracy: 0.9750\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0871 - accuracy: 0.9750\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0848 - accuracy: 0.9760\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0796 - accuracy: 0.9760\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0783 - accuracy: 0.9770\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0793 - accuracy: 0.9770\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0822 - accuracy: 0.9760\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0847 - accuracy: 0.9710\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0774 - accuracy: 0.9750\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0761 - accuracy: 0.9790\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0763 - accuracy: 0.9740\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0811 - accuracy: 0.9730\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0745 - accuracy: 0.9770\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0748 - accuracy: 0.9780\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0714 - accuracy: 0.9780\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0744 - accuracy: 0.9730\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0773 - accuracy: 0.9770\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0741 - accuracy: 0.9810\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0733 - accuracy: 0.9760\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0730 - accuracy: 0.9810\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0767 - accuracy: 0.9760\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0740 - accuracy: 0.9730\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0762 - accuracy: 0.9720\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0728 - accuracy: 0.9760\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0708 - accuracy: 0.9780\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0736 - accuracy: 0.9750\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0743 - accuracy: 0.9730\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0744 - accuracy: 0.9700\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0706 - accuracy: 0.9740\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0725 - accuracy: 0.9740\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0684 - accuracy: 0.9770\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0707 - accuracy: 0.9750\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0682 - accuracy: 0.9790\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0691 - accuracy: 0.9760\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0681 - accuracy: 0.9740\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0707 - accuracy: 0.9740\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0770 - accuracy: 0.9730\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0755 - accuracy: 0.9740\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0673 - accuracy: 0.9780\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0699 - accuracy: 0.9740\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0692 - accuracy: 0.9760\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0712 - accuracy: 0.9780\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0856 - accuracy: 0.9680\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0738 - accuracy: 0.9720\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0680 - accuracy: 0.9770\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0678 - accuracy: 0.9760\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0728 - accuracy: 0.9740\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0790 - accuracy: 0.9700\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0789 - accuracy: 0.9680\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0662 - accuracy: 0.9760\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0679 - accuracy: 0.9720\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0708 - accuracy: 0.9740\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0726 - accuracy: 0.9730\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0638 - accuracy: 0.9770\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0676 - accuracy: 0.9770\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0649 - accuracy: 0.9790\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0723 - accuracy: 0.9750\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0700 - accuracy: 0.9750\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0891 - accuracy: 0.9670\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0740 - accuracy: 0.9720\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0732 - accuracy: 0.9760\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0752 - accuracy: 0.9680\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0675 - accuracy: 0.9770\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0721 - accuracy: 0.9770\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0650 - accuracy: 0.9780\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0644 - accuracy: 0.9810\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0681 - accuracy: 0.9770\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0738 - accuracy: 0.9690\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0707 - accuracy: 0.9700\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0652 - accuracy: 0.9770\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0650 - accuracy: 0.9750\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0677 - accuracy: 0.9730\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0635 - accuracy: 0.9780\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0650 - accuracy: 0.9750\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0735 - accuracy: 0.9760\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0749 - accuracy: 0.9700\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0685 - accuracy: 0.9770\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0730 - accuracy: 0.9720\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0631 - accuracy: 0.9770\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0688 - accuracy: 0.9740\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0757 - accuracy: 0.9740\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0670 - accuracy: 0.9790\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0625 - accuracy: 0.9770\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0648 - accuracy: 0.9740\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0686 - accuracy: 0.9720\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0659 - accuracy: 0.9780\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0690 - accuracy: 0.9730\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0640 - accuracy: 0.9770\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0735 - accuracy: 0.9720\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0732 - accuracy: 0.9760\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0628 - accuracy: 0.9780\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0664 - accuracy: 0.9780\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0632 - accuracy: 0.9750\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0709 - accuracy: 0.9740\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0652 - accuracy: 0.9790\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0816 - accuracy: 0.9720\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0726 - accuracy: 0.9710\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0707 - accuracy: 0.9750\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0805 - accuracy: 0.9680\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0608 - accuracy: 0.9780\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0635 - accuracy: 0.9770\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0647 - accuracy: 0.9740\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0662 - accuracy: 0.9710\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0647 - accuracy: 0.9760\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0679 - accuracy: 0.9730\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0643 - accuracy: 0.9770\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0683 - accuracy: 0.9760\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0687 - accuracy: 0.9720\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0640 - accuracy: 0.9750\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0615 - accuracy: 0.9770\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0625 - accuracy: 0.9770\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0717 - accuracy: 0.9720\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0647 - accuracy: 0.9740\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0616 - accuracy: 0.9740\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0673 - accuracy: 0.9790\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0730 - accuracy: 0.9710\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0660 - accuracy: 0.9790\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0687 - accuracy: 0.9740\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0705 - accuracy: 0.9740\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0656 - accuracy: 0.9780\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0679 - accuracy: 0.9780\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0777 - accuracy: 0.9650\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0720 - accuracy: 0.9710\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0641 - accuracy: 0.9710\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0724 - accuracy: 0.9710\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0654 - accuracy: 0.9770\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0748 - accuracy: 0.9730\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0672 - accuracy: 0.9730\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0680 - accuracy: 0.9760\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0803 - accuracy: 0.9670\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0642 - accuracy: 0.9760\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0708 - accuracy: 0.9710\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0663 - accuracy: 0.9760\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0673 - accuracy: 0.9760\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0682 - accuracy: 0.9740\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0608 - accuracy: 0.9780\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0625 - accuracy: 0.9750\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0700 - accuracy: 0.9720\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0645 - accuracy: 0.9760\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0639 - accuracy: 0.9760\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0699 - accuracy: 0.9700\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0771 - accuracy: 0.9710\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0728 - accuracy: 0.9720\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0761 - accuracy: 0.9710\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0663 - accuracy: 0.9770\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0648 - accuracy: 0.9740\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0658 - accuracy: 0.9750\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0711 - accuracy: 0.9700\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0647 - accuracy: 0.9760\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0642 - accuracy: 0.9800\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0612 - accuracy: 0.9760\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0711 - accuracy: 0.9720\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0900 - accuracy: 0.9580\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0916 - accuracy: 0.9680\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0672 - accuracy: 0.9750\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0809 - accuracy: 0.9670\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0639 - accuracy: 0.9730\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0676 - accuracy: 0.9750\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0681 - accuracy: 0.9730\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0626 - accuracy: 0.9790\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0649 - accuracy: 0.9750\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0674 - accuracy: 0.9720\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0694 - accuracy: 0.9680\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0612 - accuracy: 0.9760\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0669 - accuracy: 0.9780\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0624 - accuracy: 0.9780\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0651 - accuracy: 0.9790\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0645 - accuracy: 0.9760\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0743 - accuracy: 0.9710\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0641 - accuracy: 0.9730\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0628 - accuracy: 0.9770\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0676 - accuracy: 0.9730\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0808 - accuracy: 0.9640\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0604 - accuracy: 0.9770\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0632 - accuracy: 0.9780\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0670 - accuracy: 0.9760\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0658 - accuracy: 0.9680\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0648 - accuracy: 0.9770\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0848 - accuracy: 0.9630\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0767 - accuracy: 0.9690\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0680 - accuracy: 0.9720\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0681 - accuracy: 0.9760\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0688 - accuracy: 0.9740\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0606 - accuracy: 0.9770\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0611 - accuracy: 0.9750\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0670 - accuracy: 0.9720\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0764 - accuracy: 0.9670\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0701 - accuracy: 0.9760\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0718 - accuracy: 0.9730\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0609 - accuracy: 0.9790\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0617 - accuracy: 0.9760\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0640 - accuracy: 0.9770\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0635 - accuracy: 0.9780\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0849 - accuracy: 0.9630\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0734 - accuracy: 0.9710\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0653 - accuracy: 0.9760\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0651 - accuracy: 0.9750\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0660 - accuracy: 0.9740\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0705 - accuracy: 0.9730\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0616 - accuracy: 0.9750\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0656 - accuracy: 0.9760\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0618 - accuracy: 0.9790\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0640 - accuracy: 0.9760\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0679 - accuracy: 0.9750\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0614 - accuracy: 0.9770\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0729 - accuracy: 0.9750\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0758 - accuracy: 0.9720\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0657 - accuracy: 0.9760\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0657 - accuracy: 0.9750\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0608 - accuracy: 0.9790\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0666 - accuracy: 0.9770\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0620 - accuracy: 0.9760\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0585 - accuracy: 0.9810\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0662 - accuracy: 0.9760\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0616 - accuracy: 0.9760\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0608 - accuracy: 0.9780\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0607 - accuracy: 0.9780\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0657 - accuracy: 0.9750\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0646 - accuracy: 0.9750\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0701 - accuracy: 0.9760\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0712 - accuracy: 0.9710\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0708 - accuracy: 0.9750\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0717 - accuracy: 0.9690\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0870 - accuracy: 0.9640\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0793 - accuracy: 0.9670\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0712 - accuracy: 0.9770\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0603 - accuracy: 0.9750\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0638 - accuracy: 0.9760\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0629 - accuracy: 0.9760\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0709 - accuracy: 0.9720\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0691 - accuracy: 0.9760\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0670 - accuracy: 0.9690\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0628 - accuracy: 0.9780\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0612 - accuracy: 0.9780\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0643 - accuracy: 0.9760\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0722 - accuracy: 0.9690\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0700 - accuracy: 0.9740\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0794 - accuracy: 0.9680\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0623 - accuracy: 0.9740\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0635 - accuracy: 0.9750\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0638 - accuracy: 0.9770\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0668 - accuracy: 0.9760\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0702 - accuracy: 0.9720\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0687 - accuracy: 0.9740\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0645 - accuracy: 0.9770\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0817 - accuracy: 0.9660\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0594 - accuracy: 0.9780\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0761 - accuracy: 0.9690\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0622 - accuracy: 0.9760\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0612 - accuracy: 0.9780\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0725 - accuracy: 0.9710\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0614 - accuracy: 0.9760\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0621 - accuracy: 0.9780\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0784 - accuracy: 0.9730\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0816 - accuracy: 0.9680\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0739 - accuracy: 0.9700\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0737 - accuracy: 0.9730\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0654 - accuracy: 0.9770\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0643 - accuracy: 0.9770\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0644 - accuracy: 0.9750\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0701 - accuracy: 0.9730\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0706 - accuracy: 0.9730\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0672 - accuracy: 0.9770\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0618 - accuracy: 0.9760\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0652 - accuracy: 0.9740\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0659 - accuracy: 0.9740\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0608 - accuracy: 0.9750\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0619 - accuracy: 0.9750\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0679 - accuracy: 0.9770\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0792 - accuracy: 0.9670\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0660 - accuracy: 0.9730\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0647 - accuracy: 0.9710\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0619 - accuracy: 0.9760\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0658 - accuracy: 0.9750\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0615 - accuracy: 0.9780\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0616 - accuracy: 0.9780\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0658 - accuracy: 0.9730\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0641 - accuracy: 0.9770\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0604 - accuracy: 0.9770\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0621 - accuracy: 0.9760\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0625 - accuracy: 0.9770\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0788 - accuracy: 0.9700\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0631 - accuracy: 0.9770\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0641 - accuracy: 0.9750\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0648 - accuracy: 0.9760\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0830 - accuracy: 0.9680\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0707 - accuracy: 0.9720\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0761 - accuracy: 0.9700\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0655 - accuracy: 0.9780\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0613 - accuracy: 0.9770\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0665 - accuracy: 0.9720\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0631 - accuracy: 0.9760\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0674 - accuracy: 0.9730\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0651 - accuracy: 0.9760\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0723 - accuracy: 0.9760\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0648 - accuracy: 0.9750\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0666 - accuracy: 0.9750\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0662 - accuracy: 0.9710\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0652 - accuracy: 0.9780\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0712 - accuracy: 0.9750\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0740 - accuracy: 0.9770\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0641 - accuracy: 0.9760\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0684 - accuracy: 0.9800\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0726 - accuracy: 0.9730\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0641 - accuracy: 0.9760\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0679 - accuracy: 0.9740\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0742 - accuracy: 0.9640\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0632 - accuracy: 0.9740\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0717 - accuracy: 0.9730\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0674 - accuracy: 0.9770\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0711 - accuracy: 0.9700\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0608 - accuracy: 0.9780\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0656 - accuracy: 0.9760\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0702 - accuracy: 0.9740\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0725 - accuracy: 0.9770\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0650 - accuracy: 0.9750\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0650 - accuracy: 0.9710\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0642 - accuracy: 0.9770\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0623 - accuracy: 0.9790\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0631 - accuracy: 0.9770\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0647 - accuracy: 0.9760\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0637 - accuracy: 0.9720\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0630 - accuracy: 0.9770\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0620 - accuracy: 0.9760\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0643 - accuracy: 0.9780\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0634 - accuracy: 0.9790\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0806 - accuracy: 0.9650\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0650 - accuracy: 0.9720\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0612 - accuracy: 0.9760\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0718 - accuracy: 0.9750\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.0582 - accuracy: 0.9800\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0741 - accuracy: 0.9720\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0693 - accuracy: 0.9720\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0671 - accuracy: 0.9750\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0642 - accuracy: 0.9780\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0636 - accuracy: 0.9770\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0798 - accuracy: 0.9660\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0703 - accuracy: 0.9760\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0684 - accuracy: 0.9700\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0626 - accuracy: 0.9770\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0648 - accuracy: 0.9780\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0645 - accuracy: 0.9740\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0647 - accuracy: 0.9770\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0723 - accuracy: 0.9750\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0715 - accuracy: 0.9750\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0627 - accuracy: 0.9750\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0655 - accuracy: 0.9740\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0623 - accuracy: 0.9750\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0720 - accuracy: 0.9730\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0620 - accuracy: 0.9780\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0630 - accuracy: 0.9740\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0646 - accuracy: 0.9760\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0699 - accuracy: 0.9720\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.0732 - accuracy: 0.9740\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0761 - accuracy: 0.9720\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0683 - accuracy: 0.9700\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0643 - accuracy: 0.9800\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0669 - accuracy: 0.9770\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0640 - accuracy: 0.9760\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0611 - accuracy: 0.9760\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0626 - accuracy: 0.9780\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0631 - accuracy: 0.9760\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0613 - accuracy: 0.9790\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0610 - accuracy: 0.9760\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0636 - accuracy: 0.9740\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.0733 - accuracy: 0.9720\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.0669 - accuracy: 0.9730\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0653 - accuracy: 0.9750\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0638 - accuracy: 0.9750\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0687 - accuracy: 0.9720\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0654 - accuracy: 0.9720\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0673 - accuracy: 0.9730\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0720 - accuracy: 0.9720\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0649 - accuracy: 0.9780\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0627 - accuracy: 0.9770\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0645 - accuracy: 0.9750\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0638 - accuracy: 0.9750\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0690 - accuracy: 0.9750\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0648 - accuracy: 0.9750\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0676 - accuracy: 0.9740\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0715 - accuracy: 0.9710\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0626 - accuracy: 0.9760\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0662 - accuracy: 0.9780\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0656 - accuracy: 0.9750\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0628 - accuracy: 0.9810\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0716 - accuracy: 0.9700\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0610 - accuracy: 0.9740\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0615 - accuracy: 0.9770\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0646 - accuracy: 0.9740\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0642 - accuracy: 0.9770\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0613 - accuracy: 0.9750\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0624 - accuracy: 0.9770\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0626 - accuracy: 0.9780\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0613 - accuracy: 0.9780\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0712 - accuracy: 0.9720\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0612 - accuracy: 0.9750\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0640 - accuracy: 0.9720\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0700 - accuracy: 0.9740\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0682 - accuracy: 0.9750\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0670 - accuracy: 0.9770\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0789 - accuracy: 0.9710\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0670 - accuracy: 0.9720\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0629 - accuracy: 0.9770\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0716 - accuracy: 0.9770\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0652 - accuracy: 0.9750\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0782 - accuracy: 0.9690\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0728 - accuracy: 0.9690\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0673 - accuracy: 0.9750\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0646 - accuracy: 0.9780\n",
      "Epoch 460/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0628 - accuracy: 0.9730\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0666 - accuracy: 0.9770\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1010 - accuracy: 0.9590\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0762 - accuracy: 0.9720\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0743 - accuracy: 0.9720\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0734 - accuracy: 0.9690\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0647 - accuracy: 0.9730\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0677 - accuracy: 0.9760\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0650 - accuracy: 0.9760\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0681 - accuracy: 0.9740\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0640 - accuracy: 0.9730\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0663 - accuracy: 0.9740\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0703 - accuracy: 0.9720\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0765 - accuracy: 0.9650\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0763 - accuracy: 0.9690\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0653 - accuracy: 0.9770\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0622 - accuracy: 0.9760\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0766 - accuracy: 0.9720\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0698 - accuracy: 0.9730\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0618 - accuracy: 0.9770\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0645 - accuracy: 0.9750\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0696 - accuracy: 0.9730\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0651 - accuracy: 0.9760\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0651 - accuracy: 0.9770\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0637 - accuracy: 0.9750\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0909 - accuracy: 0.9710\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0686 - accuracy: 0.9780\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0722 - accuracy: 0.9730\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0699 - accuracy: 0.9730\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0668 - accuracy: 0.9750\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0629 - accuracy: 0.9780\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0649 - accuracy: 0.9770\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0648 - accuracy: 0.9780\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0649 - accuracy: 0.9750\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0770 - accuracy: 0.9700\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0628 - accuracy: 0.9750\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0674 - accuracy: 0.9740\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0746 - accuracy: 0.9740\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0657 - accuracy: 0.9750\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0698 - accuracy: 0.9710\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0614 - accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 1, input_shape=(2,), activation='sigmoid'))\n",
    "\"\"\"\n",
    "We need to specify what kind of optimizer we're going to use what kind of error function\n",
    "and tend to cross entropy and the metrics which is a function that you use to judge the \n",
    "performance of our model. So the optimizer will use ATOM were a lost function will equal \n",
    "some form of cross entropy which as you know is the the last function that will help determine the error.\n",
    "\"\"\"\n",
    "adam = Adam(lr = 0.1)\n",
    "\n",
    "\"\"\"\n",
    "Now since we're only dealing with two classes we'd expect a binary outcome of zeros \n",
    "and ones and thus we will be using binary across entropy by unary cross entropy. \n",
    "This calculates the cross entropy value for binary classification problems.\n",
    "(If we were dealing with three or more cost you would then use categorical across an \n",
    "attribute which calculates the cross entropy value for multiclass classification.)\n",
    "\n",
    "As for the metrics a metric is very similar to a loss function. However unlike the \n",
    "error function whose results as we saw are constantly back propagate it to minimize\n",
    "the error of our model. There is result from evaluating a metric are not used to train the \n",
    "model but simply to judge the performance at every park which is going to equal a list of functions.\n",
    "In our case we're interested in the accuracy which calculates the accuracy of how often the \n",
    "models predictions match the labels of our data.\n",
    "\"\"\"\n",
    "model.compile(adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\"\"\"\n",
    "Verbose is equal to one but that will do is simply display a progress bar of information \n",
    "relating to the performance of our model at each epoch.\n",
    "An epoch simply refers to whatever it iterates over the entire data set of points and \n",
    "labels to try and separate our data in discrete classes based on their assigned labels.\n",
    "So every time it iterates over the entire data set of points that is an epoch.\n",
    "However one IPAC is too big to feed to the computer all at once. So we need to divide it\n",
    "into several smaller batches. More specifically it would be a bot size 50.\n",
    "\"\"\"\n",
    "h = model.fit(x=X, y=y, verbose=1, batch_size=50, epochs=500, shuffle='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x636ae3320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall the concept of gradient sets which updates the weights and biases of our network in the direction \n",
    "that decreases the air function the most. It's an iterative process which is why we need to pass the full \n",
    "dataset through our and your own that work multiple times to ensure an optimized results.\n",
    "\n",
    "In other words we need more than one epochs. If you simply specify one Pawk epoches equal to one that \n",
    "leads to the under fitting which doesn't capture the underlying trend of data as the number of epochs \n",
    "increase the more times it's able to update the weights of our neural network minimizing the error and \n",
    "thus producing the optimal results at the same time. You don't want to pass in too many epochs since \n",
    "that can lead to overfitting which is a modeling error that occurs when a function is too closely fit \n",
    "to a limited set of data points. This overfitting we're going to see a lot of examples of it.\n",
    "\n",
    "Once we deal with deeper neural networks now since we're dealing with a linear classification of relatively \n",
    "small complexity as opposed to a deeper neural network with a higher complexity which we will make use of \n",
    "later on in the course. One might think that overfitting isn't much of an issue although a linear classifier \n",
    "can absolutely be overfit if used without proper care.\n",
    "\n",
    "However if you have the right number of box it's going to model your data just fine. Unfortunately there isn't \n",
    "really the right answer as to how many epochs you should have. It really just depends on your dataset. So what\n",
    "will do is we'll just specify the possible to 500. It'll go through all of our data 500 times now 500 epochs \n",
    "is a bit much I'll admit. Realistically we're not going to need more than 10 epochs or so. But for the sake of \n",
    "demonstrating the training process and seeing a descriptive plot will extend the training process to go with 500 epochs.\n",
    "No don't actually get used to specifying too many POCs you'll see that this can get pretty bad once I demonstrate\n",
    "this in the convolutional neural network section as the model can start to overfit our training data and isn't able\n",
    "to generalize itself to new data. But regardless we'll cross that bridge when we get there.\n",
    "Now finally we're gonna set shuffle is equal to true this one should be new to you so as to shuffle our training\n",
    "before it Apoc as we use gradient descent to update the weights in the direction that decreases the area the most\n",
    "as it keeps minimizing the air it'll tend to get stuck in a local minimum of some sort rather than the \n",
    "absolute minimum. And our goal is to minimize the error the most. So what you want to do is ensure the \n",
    "absolute minimum of your last function to decrease the air as much as possible thereby maximizing the accuracy of \n",
    "our model. And so if you are dealing with static training data that's unchanged over all training iterations.\n",
    "\n",
    "Gradient descent algorithms will tend to get stuck in these local minima and the solution to this is to simply\n",
    "shuffle your training data. So what that does is it shuffles the rows in your data. And for each given iteration trains only a subset of them.\n",
    "This ensures that the subset of training it changes with every single iteration and thus if our algorithm \n",
    "worked to get stuck it would simply help and kind of bounce off the local minimum right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model):\n",
    "    x_span = np.linspace(min(X[:, 0]) -1, max(X[:, 0]))\n",
    "    y_span = np.linspace(min(X[:, 1]) -1, max(X[:, 1]))\n",
    "    # Square two dimensional array that is trained\n",
    "    # from the number high dot mesh grid function\n",
    "    xx, yy = np.meshgrid(x_span, y_span)\n",
    "    xx_, yy_ = xx.ravel(), yy.ravel()\n",
    "    grid = np.c_[xx_,yy_]\n",
    "    prediction_func = model.predict(grid)\n",
    "#   reshape array to have the same dimensions as xx or yy\n",
    "    z = prediction_func.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAUE0lEQVR4nO3dfaxkd13H8feHListULu1tmJbaCFQtU0FXAkPotgqqUJa/9AIUdIoZiNRniJiCYnG/wgQH4JG00ApgVKDpQJptLZBYmOE4m2l0LJUULDsUtiSXR7kQaj9+sfMLLd379yZO2dmzjkz71eyufeemTvz3Xv3fvZ7v3PO75eqQpLUP49ouwBJ0mwMcEnqKQNcknrKAJeknjLAJamn9izzyfY+4uQ6ec+py3xKSeq9r333yJer6ge3Hl9qgJ+851SefeavLvMpJan3bj78lv/e7rgjFEnqKQNcknrKAJeknjLAJamnDHBJ6ikDXJJ6ygCXpJ4ywCWpp5Ya4A+d/MhlPp0krbSld+DfuuhsvnXR2ct+WklaOa2NUAxySWqm9Rm4QS5Js2k9wEcMcknanc4E+IhBLknTmRjgSa5JciTJ3VuOvzzJvUnuSfLGaZ7s/x6VqQszyCVpZ9N04NcCl20+kORngSuAi6vqQuDN0z7hsQv2cuyCvVMXaJBL0vYmBnhV3QYc3XL4ZcAbqup/h/c5stsnNsglqZlZZ+BPAZ6b5PYk/5zkJ8fdMcmBJBtJNh781jdOuN0gl6TZzBrge4B9wDOB3wfek2TbAXdVXV1V+6tqf0579NgHNMglaXdmDfBDwI018FHgIeCMaT7x6096iK8/6aGxtxvkkjSdWQP8fcAlAEmeAuwFvrybBzDIJamZibvSJ7keeB5wRpJDwB8B1wDXDE8t/A5wZVXVLAWMQvyx/7n9/yWbQ3zfvd+Z+HibQ/zkuw/PUpIk9cLEAK+qF4+56dd3+2Qnfd//jb1tUpDD98J8miCH74W5QS5pFS39SszHnP9VHnP+V8fePmm0ArONVyRp1bR2Kf2yg9wZuaRVM3GEsmijEP+fz37/trfPe7TijFzSqujMYlZtjVbsyiX11VID/NS93+b5j793x/sY5JI0nVY68Oc//l6DXJIaanWEYpBL0uw6MQM3yCVp9zoR4CMGuSRNr1MBPmKQS9JknQzwEYNcksZb6oU8P3DS/8z0eaMQv+W+C8beZ9oLgmDywlmutSKpD5Z+JeZL9v3r8fffeezZu/rceQQ5TL8CokEuqctaHaG8ZN+/PizQpzWP0Qq4Jrmkfmt9LRT4Xle+yI4cZl9vxY5cUhd16kXMRXbk0PwFTztySV0yMcCTXJPkyHD3na23vSZJJZlqP8xp9SXIXcpWUpum6cCvBS7bejDJucDPA/fNuabjZglxWF6Qg2uSS2rPNFuq3ZbkvG1u+lPgtcD751zTwyz6rBVob01yZ+SSmphpBp7kcuBwVd01xX0PJNlIsnHs6M7d7CRdH62AHbmk5ck0m8kPO/CbquqiJKcAHwKeX1VfTfI5YH9VfXnS41x48d56901nNat4k9125COTOvKRnc4lh5078pFpz1wZsSuXtNXNh99yR1Xt33p8ltMInwScD9yVBOAc4M4kz6iqLzYrc3eann4I87m6c16jFXC8Iml6uw7wqvoEcObo49104Isya5DDfC/TN8glLdM0pxFeD3wYuCDJoSQvXXxZs5l1Rg4unCWpf6aagc/LvGfgk8w6I4fp5uTOyCUtw7gZeKeuxJw3O3JJq2ylA3zEIJe0itYiwEcMckmrZK0CfMQgl7QK1jLARwxySX3WifXA29aV88jBNcklTW+tO/Ct2u7IwTXJJU3PDnwby+rIwV2CJM3ODnwHi+7IwV2CJM3ODnwKi+7Iofl6K5tD3DXJpfVggO9CnzaX2O1oBQxzqW8cocyo65tL7Ha0AjhakXrGDryhrq9JPutoBezIpa6zA5+Ttk9B9KIgaf0Y4HNmkEtalmk2dLgmyZEkd2869qYkn0ry8SR/l+S0xZbZPwa5pEWbpgO/Frhsy7FbgYuq6mLgP4DXzbmulWGQS1qUiQFeVbcBR7ccu6WqHhx++BEGGxtrBwa5pHmbxwz8N4F/mMPjrAWDXNK8NArwJK8HHgSu2+E+B5JsJNk4dnTn4FgnBrmkpqba1DjJecBNVXXRpmNXAr8NXFpV35zmyZa9qXGfuAGzpHHGbWo804U8SS4D/gD4mWnDWzvryprkky7RB1dAlLpimtMIrwc+DFyQ5FCSlwJ/ATwWuDXJx5L89YLrXBuOViRNa6oRyrw4Qtk9RyuS5jpC0fJ0ZbQCbi4hdY0B3hOLXsp2UpCDuwRJXeNaKD20yKVs3bdT6g8DvMcMcmm9GeArwCCX1pMz8BXSdHOJaWbk0HxzCWfk0nzYga+gVdvuzY5c2p4d+ApbZEcO7W33ZkcuDdiBr4Gud+Swu67cjlwaMMDXiEEurRZHKGuo6WgFurVwlqMVrSs78DXWdOGsSdrqyO3KtS7swLVyHTnYlWs92IHrOJeylfrFANcJDHKpHwxwjWWQS902zY481yQ5kuTuTcdOT3Jrkk8P3+5bbJlqk0EuddM0Hfi1wGVbjl0FfLCqngx8cPixVpxBLnXLxACvqtuAo1sOXwG8Y/j+O4BfmnNd6jCDXOqGWWfgZ1XV/QDDt2eOu2OSA0k2kmwcO7rzD536xSCX2rXwFzGr6uqq2l9V+/ed7mumq8ggl9ox64U8X0ryuKq6P8njgCPzLEr95AbM0nLN2hJ/ALhy+P6VwPvnU45WwbI6ctck17pLVe18h+R64HnAGcCXgD8C3ge8B3g8cB/wK1W19YXOE1x48d56901nNSxZfTRLVw6T1yQfGdeVj+x0mT5M35GP2JFrmW4+/JY7qmr/1uMTA3yeDPD1NmuIg0Gu9TYuwF3MSkuz6Bk5uEuQ1osBrqXbPB/v6nZvMNua5GCYa3kMcLXKpWyl2XlitjrBc8ml3TPA1SkGuTQ9A1ydZJBLkxng6jSDXBrPAFcvGOTSiQxw9YpBLn2PAa5eMsglA1w9Z5BrnRngWgkGudaRAa6VYpBrnRjgWkkGudaBa6FopblLkFaZHbjWQtsdObhLkOavUQee5NXAbwEFfAL4jar69jwKkxZh0UvZTurIYfo1ye3INcnMHXiSs4FXAPur6iLgJOBF8ypMWrRZu3I7cnVF0xHKHuDkJHuAU4AvNC9JWi6DXH018wilqg4neTODTY2/BdxSVbdsvV+SA8ABgMedfdKsTyctXNPNJaYZrUDz7d4crWhk5k2Nk+wD3gv8KvAV4G+BG6rqXeM+x02N1SezbsLsBsyat3GbGjcZofwc8NmqeqCqvgvcCMy+7bjUMYscrUDzc8lHo5VpxyuOVlZPkwC/D3hmklOSBLgUODifsqTu6HqQw+7m5Ab56pg5wKvqduAG4E4GpxA+Arh6TnVJnWOQq2tmnoHPwhm4VknXZ+TgnHxVjJuBeym9NKOmZ63AfC7T3ynIPXNltXkpvdRQ25fpu3DW+jLApTkxyLVsBrg0Zwa5lsUAlxbEINeiGeDSghnkWhQDXFoSg1zzZoBLS2aQa14McKklBrmaMsCllhnkmpVXYkod4QbM2i07cKlj2u7IwV2C+sIOXOqoZXXk4C5BfWWASx23uRtfxHZv0HzhLIO8HQa41COL3LcT5hfkMF2YG+TNNJqBJzktyQ1JPpXkYJJnzaswSeMtckYO7W0u4Zx8d5p24H8O3FxVv5xkL3DKHGqSNIU+jFbA8coiNdmV/lTgLuCJNeWDuCOPtFiz7hIE0+0U5C5B7VjErvRPBB4A3p7k35O8NcmjGzyepIbaPgXRi4KWq0mA7wGeDvxVVT0N+AZw1dY7JTmQZCPJxrGjO39jJc2HQb4emoxQfgj4SFWdN/z4ucBVVfWCcZ/jCEVqh6OVfpv7CKWqvgh8Psnou3sp8MlZH0/S4tiRr6amZ6G8HLhueAbKfwG/0bwkSYvSlfVWPGtlPmYeoczCEYrULY5W+mERZ6FI6jlHK/1mgEsyyHvKAJd0nEHeLwa4pBMY5P3gaoSSxurKWSvgUrbbsQOXNFHbHTm4S9B2DHBJUzPIu8URiqRdW/RStm73Nh07cEmNzNqVL2tziVXuyA1wSXNhkC+fAS5prgzy5THAJS2EQb54vogpaaFmPZd8Wft2bg7xaV7w7NKLnXbgkpai6x057K4r70JHbgcuaam63pHD7k5B3Bziy+7KDXBJrWga5ODmEo1HKElOGu5Kf9M8CpK0Xtq+urPPC2fNYwb+SuDgHB5H0hozyHevUYAnOQd4AfDW+ZQjad0Z5NNr2oH/GfBaYOzfNsmBJBtJNo4d3fmLIkkjBvlkMwd4khcCR6rqjp3uV1VXV9X+qtq/73TPWpS0Owb5eE0S9TnA5Uk+B/wNcEmSdzWuSJK2YZCfKFU18ycff5DkecBrquqFO93vwov31rtvOqvx80nSLLsEjUw6lxzGn344stPphyPTnn44Mu70w5sPv+WOqtq/9bgzDUm9ZEc+pw58Wnbgkhal7Y4cJnfls3bk4zpwr8SUtBKWtUvQTkG+qF2CGHNhpyMUSStn1fbtHMcOXNJKmnWtFejuvp1bGeCSVtqigxyWvyb5iAEuaS0sekYOy18B0Rm4pLWzKptLGOCS1lZfgnwcRyiS1l4fNpfYjh24JA314erOzQxwSdqiL0HuCEWSxljWueSTRivj2IFL0gRtd+TjGOCSNKWuBbkBLkm71JUgdwYuSTNa5nor27EDl6SGFt2Rj9NkU+Nzk3woycEk9yR55ayPJUmrYNlB3mSE8iDwe1V1Z5LHAnckubWqPtngMSWp95axAiI06MCr6v6qunP4/teBg8Ds2ytL0opZdEc+lxl4kvOApwG3b3PbgSQbSTaOHZ3+ElFJWhVNg3ycxgGe5DHAe4FXVdXXtt5eVVdX1f6q2r/vdF8zlbS+mgT5dhqdRpjkkQzC+7qqunE+JUnSamuyucRmTc5CCfA24GBV/cnMFUjSGmvSlTeZaTwHeAlwSZKPDf/8YoPHk6S1NUuQzzxCqap/ATLr50uSTrSbUxB9VVGSOmiajtwAl6QO2ynEDXBJ6ikDXJJ6ygCXpJ4ywCWppwxwSeopA1ySesoAl6SeMsAlqacMcEnqKQNcknrKAJeknjLAJamnDHBJ6ikDXJJ6qlGAJ7ksyb1JPpPkqnkVJUmarMmemCcBfwn8AvBjwIuT/Ni8CpMk7axJB/4M4DNV9V9V9R3gb4Ar5lOWJGmSJgF+NvD5TR8fGh57mCQHkmwk2Th29KEGTydJ2mzmTY3ZfkPjOuFA1dXA1QBJHnjqEw79d4Pn3OwM4Mtzeqx562ptXa0LultbV+uC7tbW1bqgu7VNqusJ2x1sEuCHgHM3fXwO8IWdPqGqfrDB8z1Mko2q2j+vx5unrtbW1bqgu7V1tS7obm1drQu6W9usdTUZofwb8OQk5yfZC7wI+ECDx5Mk7cLMHXhVPZjkd4F/BE4Crqmqe+ZWmSRpR01GKFTV3wN/P6daduvqlp53Gl2trat1QXdr62pd0N3auloXdLe2mepK1QmvO0qSesBL6SWppwxwSeqp3gV4knOTfCjJwST3JHll2zVtluSkJP+e5Ka2a9ksyWlJbkjyqeHX7llt1wSQ5NXD7+PdSa5P8qgWa7kmyZEkd286dnqSW5N8evh2X0fqetPwe/nxJH+X5LRl1zWutk23vSZJJTmjK3Uleflw/aZ7krxx2XWNqy3JU5N8JMnHhhc+PmOax+pdgAMPAr9XVT8KPBP4nY6twfJK4GDbRWzjz4Gbq+pHgB+nAzUmORt4BbC/qi5icDbTi1os6Vrgsi3HrgI+WFVPBj44/HjZruXEum4FLqqqi4H/AF637KKGruXE2khyLvDzwH3LLmjoWrbUleRnGSz3cXFVXQi8uYW6YPuv2RuBP66qpwJ/OPx4ot4FeFXdX1V3Dt//OoMgOuES/jYkOQd4AfDWtmvZLMmpwE8DbwOoqu9U1Vfareq4PcDJSfYApzDhYrBFqqrbgKNbDl8BvGP4/juAX1pqUWxfV1XdUlUPDj/8CIML6ZZuzNcM4E+B17LN1dnLMKaulwFvqKr/Hd7nyNILY2xtBZw6fP/7mfLnoHcBvlmS84CnAbe3W8lxf8bgH23XFn15IvAA8PbheOetSR7ddlFVdZhBF3QfcD/w1aq6pd2qTnBWVd0Pg+YBOLPlerbzm8A/tF3ESJLLgcNVdVfbtWzxFOC5SW5P8s9JfrLtgjZ5FfCmJJ9n8DMx1W9UvQ3wJI8B3gu8qqq+1oF6Xggcqao72q5lG3uApwN/VVVPA75BO6OAhxnOk68Azgd+GHh0kl9vt6p+SfJ6BmPF69quBSDJKcDrGYwBumYPsI/B6PX3gfck2W5Npza8DHh1VZ0LvJrhb8uT9DLAkzySQXhfV1U3tl3P0HOAy5N8jsHSupckeVe7JR13CDhUVaPfVG5gEOht+zngs1X1QFV9F7gReHbLNW31pSSPAxi+beXX7u0kuRJ4IfBr1Z0LOp7E4D/ku4Y/C+cAdyb5oVarGjgE3FgDH2Xwm/LSX2Ad40oG//4B/pbBct0T9S7Ah/9jvg04WFV/0nY9I1X1uqo6p6rOY/BC3D9VVSe6yar6IvD5JBcMD10KfLLFkkbuA56Z5JTh9/VSOvDi6hYfYPDDxfDt+1us5bgklwF/AFxeVd9su56RqvpEVZ1ZVecNfxYOAU8f/hts2/uASwCSPAXYS3dWJvwC8DPD9y8BPj3VZ1VVr/4AP8Vg4P9x4GPDP7/Ydl1banwecFPbdWyp6anAxvDr9j5gX9s1Dev6Y+BTwN3AO4Hva7GW6xnM4r/LIHheCvwAg7NPPj18e3pH6voMg/X4Rz8Df92Vr9mW2z8HnNGFuhgE9ruG/9buBC7pytdsmGt3AHcxeE3vJ6Z5LC+ll6Se6t0IRZI0YIBLUk8Z4JLUUwa4JPWUAS5JPWWAS1JPGeCS1FP/Dypv36/IR9vVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
