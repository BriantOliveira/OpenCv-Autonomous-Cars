{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\"\"\"Atom optimization algorithm is a combination of two other extensions a \n",
    "stochastic gradient descent notably Ada grad and armis prop and is a very efficient stochastic \n",
    "optimization method in updating the weights of our network.\"\"\"\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1126000f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_pts = 500\n",
    "np.random.seed(0)\n",
    "Xa = np.array([np.random.normal(13, 2, n_pts),\n",
    "               np.random.normal(12, 2, n_pts)]).T\n",
    "Xb = np.array([np.random.normal(8, 2, n_pts),\n",
    "               np.random.normal(6, 2, n_pts)]).T\n",
    " \n",
    "X = np.vstack((Xa, Xb))\n",
    "y = np.matrix(np.append(np.zeros(n_pts), np.ones(n_pts))).T\n",
    " \n",
    "plt.scatter(X[:n_pts,0], X[:n_pts,1])\n",
    "plt.scatter(X[n_pts:,0], X[n_pts:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 1.0564 - accuracy: 0.4730\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.5242 - accuracy: 0.7760\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.3827 - accuracy: 0.8960\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.3309 - accuracy: 0.9070\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.2886 - accuracy: 0.9310\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.2541 - accuracy: 0.9470\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.2316 - accuracy: 0.9530\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.2073 - accuracy: 0.9630\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.1952 - accuracy: 0.9670\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.1812 - accuracy: 0.9600\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1686 - accuracy: 0.9610\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1576 - accuracy: 0.9660\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1514 - accuracy: 0.9650\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1415 - accuracy: 0.9750\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.1350 - accuracy: 0.9710\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.1300 - accuracy: 0.9750\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1303 - accuracy: 0.9620\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1280 - accuracy: 0.9660\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.1191 - accuracy: 0.9750\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1121 - accuracy: 0.9760\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.1100 - accuracy: 0.9790\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1070 - accuracy: 0.9750\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.1061 - accuracy: 0.9780\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.1028 - accuracy: 0.9730\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0992 - accuracy: 0.9740\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.1085 - accuracy: 0.9640\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0983 - accuracy: 0.9740\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0931 - accuracy: 0.9780\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.0976 - accuracy: 0.9740\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0906 - accuracy: 0.9740\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0895 - accuracy: 0.9760\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0907 - accuracy: 0.9740\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0903 - accuracy: 0.9770\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0868 - accuracy: 0.9740\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0867 - accuracy: 0.9720\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0838 - accuracy: 0.9750\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0822 - accuracy: 0.9770\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.0861 - accuracy: 0.9740\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.0889 - accuracy: 0.9700\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0818 - accuracy: 0.9720\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0799 - accuracy: 0.9790\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0805 - accuracy: 0.9760\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0873 - accuracy: 0.9700\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0790 - accuracy: 0.9760\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0774 - accuracy: 0.9730\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.0759 - accuracy: 0.9770\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0815 - accuracy: 0.9790\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0826 - accuracy: 0.9750\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0802 - accuracy: 0.9730\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0780 - accuracy: 0.9740\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0787 - accuracy: 0.9710\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0762 - accuracy: 0.9750\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.0777 - accuracy: 0.9740\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 0.0760 - accuracy: 0.9750\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0756 - accuracy: 0.9720\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0730 - accuracy: 0.9790\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0729 - accuracy: 0.9760\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0708 - accuracy: 0.9770\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0715 - accuracy: 0.9760\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0776 - accuracy: 0.9740\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0745 - accuracy: 0.9730\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0716 - accuracy: 0.9750\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0697 - accuracy: 0.9760\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0689 - accuracy: 0.9780\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0696 - accuracy: 0.9770\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0746 - accuracy: 0.9730\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0686 - accuracy: 0.9750\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0765 - accuracy: 0.9740\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0714 - accuracy: 0.9760\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0690 - accuracy: 0.9750\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0679 - accuracy: 0.9760\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0690 - accuracy: 0.9770\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0709 - accuracy: 0.9770\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0671 - accuracy: 0.9760\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0743 - accuracy: 0.9710\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0702 - accuracy: 0.9760\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0679 - accuracy: 0.9800\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0663 - accuracy: 0.9760\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0727 - accuracy: 0.9760\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.0834 - accuracy: 0.9660\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0666 - accuracy: 0.9780\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0666 - accuracy: 0.9770\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.0754 - accuracy: 0.9700\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0667 - accuracy: 0.9780\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.0710 - accuracy: 0.9740\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0682 - accuracy: 0.9760\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0748 - accuracy: 0.9710\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0746 - accuracy: 0.9720\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0701 - accuracy: 0.9740\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0647 - accuracy: 0.9770\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0684 - accuracy: 0.9740\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0664 - accuracy: 0.9790\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0726 - accuracy: 0.9730\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0732 - accuracy: 0.9690\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0752 - accuracy: 0.9750\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0658 - accuracy: 0.9760\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0674 - accuracy: 0.9730 0s - loss: 0.0700 - accuracy: 0.97\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0668 - accuracy: 0.9760\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0702 - accuracy: 0.9740\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0807 - accuracy: 0.9650\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0729 - accuracy: 0.9750\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0667 - accuracy: 0.9750\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0621 - accuracy: 0.9770\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0662 - accuracy: 0.9760\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0834 - accuracy: 0.9700\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0726 - accuracy: 0.9700\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0755 - accuracy: 0.9700\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0660 - accuracy: 0.9770\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0647 - accuracy: 0.9780\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0686 - accuracy: 0.9710\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0666 - accuracy: 0.9760\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0636 - accuracy: 0.9730\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0648 - accuracy: 0.9730\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0645 - accuracy: 0.9760\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0628 - accuracy: 0.9790\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0622 - accuracy: 0.9790\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0632 - accuracy: 0.9770\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0647 - accuracy: 0.9760\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0666 - accuracy: 0.9760\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0640 - accuracy: 0.9750\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0730 - accuracy: 0.9750\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0646 - accuracy: 0.9770\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0696 - accuracy: 0.9770\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0661 - accuracy: 0.9790\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0723 - accuracy: 0.9750\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0659 - accuracy: 0.9740\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0650 - accuracy: 0.9750\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0742 - accuracy: 0.9720\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0713 - accuracy: 0.9680\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0643 - accuracy: 0.9740\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0705 - accuracy: 0.9750\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0662 - accuracy: 0.9780\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0648 - accuracy: 0.9760\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0703 - accuracy: 0.9740\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0767 - accuracy: 0.9740\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0935 - accuracy: 0.9630\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0689 - accuracy: 0.9710\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0803 - accuracy: 0.9720\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0761 - accuracy: 0.9690\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0695 - accuracy: 0.9760\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0693 - accuracy: 0.9720\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0651 - accuracy: 0.9730\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0656 - accuracy: 0.9770\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0652 - accuracy: 0.9760\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0623 - accuracy: 0.9770\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0629 - accuracy: 0.9760\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0636 - accuracy: 0.9760\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0659 - accuracy: 0.9690\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0724 - accuracy: 0.9750\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0704 - accuracy: 0.9720\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0636 - accuracy: 0.9780\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0728 - accuracy: 0.9720\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0777 - accuracy: 0.9720\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0662 - accuracy: 0.9740\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0626 - accuracy: 0.9780\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0648 - accuracy: 0.9760\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0691 - accuracy: 0.9740\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0693 - accuracy: 0.9750\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0666 - accuracy: 0.9740\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0682 - accuracy: 0.9710\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0658 - accuracy: 0.9730\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0618 - accuracy: 0.9790\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0618 - accuracy: 0.9770\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0623 - accuracy: 0.9780\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0643 - accuracy: 0.9750\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0618 - accuracy: 0.9790\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0694 - accuracy: 0.9740\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0608 - accuracy: 0.9780\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0611 - accuracy: 0.9760\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0658 - accuracy: 0.9730\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0725 - accuracy: 0.9740\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0721 - accuracy: 0.9750\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0612 - accuracy: 0.9760\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0687 - accuracy: 0.9750\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0725 - accuracy: 0.9710\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0631 - accuracy: 0.9750\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0666 - accuracy: 0.9750\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0645 - accuracy: 0.9760\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0623 - accuracy: 0.9800\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0635 - accuracy: 0.9760\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0609 - accuracy: 0.9770\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0871 - accuracy: 0.9650\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0854 - accuracy: 0.9650\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0613 - accuracy: 0.9800\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0651 - accuracy: 0.9770\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0615 - accuracy: 0.9790\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0683 - accuracy: 0.9720\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0695 - accuracy: 0.9740\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0632 - accuracy: 0.9780\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0619 - accuracy: 0.9760\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0711 - accuracy: 0.9700\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0614 - accuracy: 0.9760\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0699 - accuracy: 0.9740\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0666 - accuracy: 0.9760\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0676 - accuracy: 0.9780\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0615 - accuracy: 0.9780\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0689 - accuracy: 0.9730\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0741 - accuracy: 0.9740\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0628 - accuracy: 0.9770\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0707 - accuracy: 0.9780\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0647 - accuracy: 0.9770\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0652 - accuracy: 0.9700\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0692 - accuracy: 0.9710\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0659 - accuracy: 0.9740\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0672 - accuracy: 0.9750\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0673 - accuracy: 0.9730\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0698 - accuracy: 0.9760\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0774 - accuracy: 0.9700\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0627 - accuracy: 0.9770\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0610 - accuracy: 0.9740\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0640 - accuracy: 0.9750\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0774 - accuracy: 0.9720\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0616 - accuracy: 0.9780\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0665 - accuracy: 0.9760\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0685 - accuracy: 0.9740\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0744 - accuracy: 0.9710\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0620 - accuracy: 0.9770\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0633 - accuracy: 0.9750\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0622 - accuracy: 0.9790\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0665 - accuracy: 0.9760\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0635 - accuracy: 0.9750\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0774 - accuracy: 0.9670\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0914 - accuracy: 0.9650\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0800 - accuracy: 0.9660\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0700 - accuracy: 0.9720\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0725 - accuracy: 0.9780\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0619 - accuracy: 0.9770\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0711 - accuracy: 0.9740\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.98 - 0s 45us/step - loss: 0.0644 - accuracy: 0.9780\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0638 - accuracy: 0.9750\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0674 - accuracy: 0.9720\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0725 - accuracy: 0.9700\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0724 - accuracy: 0.9750\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0606 - accuracy: 0.9770\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0655 - accuracy: 0.9770\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0704 - accuracy: 0.9730\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0695 - accuracy: 0.9730\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0654 - accuracy: 0.9710\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0688 - accuracy: 0.9750\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0665 - accuracy: 0.9740\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0637 - accuracy: 0.9740\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0770 - accuracy: 0.9710\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0862 - accuracy: 0.9720\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0799 - accuracy: 0.9700\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0625 - accuracy: 0.9760\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0627 - accuracy: 0.9770\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0642 - accuracy: 0.9770\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0634 - accuracy: 0.9740\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0787 - accuracy: 0.9690\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0623 - accuracy: 0.9770\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0616 - accuracy: 0.9780\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0609 - accuracy: 0.9750\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0691 - accuracy: 0.9720\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0697 - accuracy: 0.9740\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0630 - accuracy: 0.9790\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0622 - accuracy: 0.9770\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0675 - accuracy: 0.9760\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0633 - accuracy: 0.9770\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0639 - accuracy: 0.9770\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0838 - accuracy: 0.9680\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0777 - accuracy: 0.9700\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0633 - accuracy: 0.9720\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0720 - accuracy: 0.9730\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0691 - accuracy: 0.9710\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0632 - accuracy: 0.9750\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0673 - accuracy: 0.9760\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0661 - accuracy: 0.9750\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0649 - accuracy: 0.9770\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0769 - accuracy: 0.9700\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0709 - accuracy: 0.9700\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0627 - accuracy: 0.9780\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0657 - accuracy: 0.9780\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0782 - accuracy: 0.9700\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0655 - accuracy: 0.9760\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0607 - accuracy: 0.9780\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0620 - accuracy: 0.9780\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0629 - accuracy: 0.9760\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0627 - accuracy: 0.9760\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0619 - accuracy: 0.9770\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0636 - accuracy: 0.9780\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0672 - accuracy: 0.9750\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0660 - accuracy: 0.9720\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0627 - accuracy: 0.9760\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0646 - accuracy: 0.9770\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0664 - accuracy: 0.9750\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0637 - accuracy: 0.9760\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0634 - accuracy: 0.9780\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0679 - accuracy: 0.9740\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.0664 - accuracy: 0.9810\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0656 - accuracy: 0.9760\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0768 - accuracy: 0.9680\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0709 - accuracy: 0.9730\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0758 - accuracy: 0.9700\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0707 - accuracy: 0.9760\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0690 - accuracy: 0.9700\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0695 - accuracy: 0.9720\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0849 - accuracy: 0.9660\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0692 - accuracy: 0.9690\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0710 - accuracy: 0.9730\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0725 - accuracy: 0.9690\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0634 - accuracy: 0.9780\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0616 - accuracy: 0.9770\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0705 - accuracy: 0.9770\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0695 - accuracy: 0.9750\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0715 - accuracy: 0.9730\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0676 - accuracy: 0.9710\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0676 - accuracy: 0.9730\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0670 - accuracy: 0.9780\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0703 - accuracy: 0.9730\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0663 - accuracy: 0.9750\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0706 - accuracy: 0.9780\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0656 - accuracy: 0.9760\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0639 - accuracy: 0.9750\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0648 - accuracy: 0.9770\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0659 - accuracy: 0.9780\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0699 - accuracy: 0.9720\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0610 - accuracy: 0.9780\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.0675 - accuracy: 0.9770\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.0705 - accuracy: 0.9710\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0753 - accuracy: 0.9730\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0721 - accuracy: 0.9760\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0662 - accuracy: 0.9780\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0655 - accuracy: 0.9760\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0725 - accuracy: 0.9720\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0635 - accuracy: 0.9780\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0637 - accuracy: 0.9750\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0696 - accuracy: 0.9760\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0667 - accuracy: 0.9750\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0676 - accuracy: 0.9700\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0665 - accuracy: 0.9770\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0643 - accuracy: 0.9770\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0639 - accuracy: 0.9740\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0626 - accuracy: 0.9760\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0696 - accuracy: 0.9740\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0695 - accuracy: 0.9740\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0621 - accuracy: 0.9780\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0598 - accuracy: 0.9790\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0654 - accuracy: 0.9760\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0634 - accuracy: 0.9800\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0657 - accuracy: 0.9750\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0688 - accuracy: 0.9730\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0704 - accuracy: 0.9760\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0787 - accuracy: 0.9670\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0683 - accuracy: 0.9760\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0602 - accuracy: 0.9770\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0680 - accuracy: 0.9750\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0730 - accuracy: 0.9740\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0675 - accuracy: 0.9760\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0704 - accuracy: 0.9710\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0615 - accuracy: 0.9750\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0795 - accuracy: 0.9700\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0656 - accuracy: 0.9780\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0645 - accuracy: 0.9760\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0672 - accuracy: 0.9740\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0672 - accuracy: 0.9720\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0820 - accuracy: 0.9690\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0681 - accuracy: 0.9770\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0865 - accuracy: 0.9640\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0744 - accuracy: 0.9680\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0678 - accuracy: 0.9740\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0614 - accuracy: 0.9760\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0838 - accuracy: 0.9680\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0632 - accuracy: 0.9780\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0618 - accuracy: 0.9780\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0611 - accuracy: 0.9770\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0645 - accuracy: 0.9760\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0650 - accuracy: 0.9800\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0784 - accuracy: 0.9660\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0808 - accuracy: 0.9680\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0731 - accuracy: 0.9650\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0623 - accuracy: 0.9780\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0634 - accuracy: 0.9760\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.0689 - accuracy: 0.9730\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0671 - accuracy: 0.9740\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.0643 - accuracy: 0.9750\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0643 - accuracy: 0.9770\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0661 - accuracy: 0.9740\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0613 - accuracy: 0.9780\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0628 - accuracy: 0.9780\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0627 - accuracy: 0.9770\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0660 - accuracy: 0.9710\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0809 - accuracy: 0.9730\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0732 - accuracy: 0.9720\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0704 - accuracy: 0.9740\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0682 - accuracy: 0.9780\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0640 - accuracy: 0.9710\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0629 - accuracy: 0.9780\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0630 - accuracy: 0.9760\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0620 - accuracy: 0.9780\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0699 - accuracy: 0.9710\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0687 - accuracy: 0.9760\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0735 - accuracy: 0.9720\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0625 - accuracy: 0.9770\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0627 - accuracy: 0.9770\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0695 - accuracy: 0.9740\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0632 - accuracy: 0.9790\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0686 - accuracy: 0.9740\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0687 - accuracy: 0.9720\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0744 - accuracy: 0.9730\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0618 - accuracy: 0.9800\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0667 - accuracy: 0.9780\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0626 - accuracy: 0.9760\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0671 - accuracy: 0.9710\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0661 - accuracy: 0.9770\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0632 - accuracy: 0.9780\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.0811 - accuracy: 0.9710\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0874 - accuracy: 0.9640\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0644 - accuracy: 0.9760\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0657 - accuracy: 0.9740\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0645 - accuracy: 0.9720\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.0629 - accuracy: 0.9780\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0653 - accuracy: 0.9760\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0624 - accuracy: 0.9810\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0631 - accuracy: 0.9780\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0657 - accuracy: 0.9720\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0641 - accuracy: 0.9770\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0633 - accuracy: 0.9760\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0682 - accuracy: 0.9750\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0709 - accuracy: 0.9710\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0808 - accuracy: 0.9690\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0617 - accuracy: 0.9790\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0657 - accuracy: 0.9750\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0695 - accuracy: 0.9770\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0656 - accuracy: 0.9730\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0662 - accuracy: 0.9780\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.98 - 0s 35us/step - loss: 0.0636 - accuracy: 0.9770\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0635 - accuracy: 0.9760\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0635 - accuracy: 0.9740\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0614 - accuracy: 0.9790\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0715 - accuracy: 0.9710\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0674 - accuracy: 0.9770\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0680 - accuracy: 0.9780\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0719 - accuracy: 0.9730\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0626 - accuracy: 0.9790\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0616 - accuracy: 0.9790\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0656 - accuracy: 0.9770\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0608 - accuracy: 0.9770\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0679 - accuracy: 0.9740\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0709 - accuracy: 0.9710\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0783 - accuracy: 0.9680\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0889 - accuracy: 0.9660\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0674 - accuracy: 0.9740\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.0759 - accuracy: 0.9730\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0792 - accuracy: 0.9740\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0669 - accuracy: 0.9740\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0668 - accuracy: 0.9710\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0654 - accuracy: 0.9770\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0760 - accuracy: 0.9710\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0633 - accuracy: 0.9740\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.0681 - accuracy: 0.9760\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.0665 - accuracy: 0.9730\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0671 - accuracy: 0.9750\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0617 - accuracy: 0.9770\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0643 - accuracy: 0.9770\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0628 - accuracy: 0.9770\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.0689 - accuracy: 0.9720\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0605 - accuracy: 0.9760\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0672 - accuracy: 0.9740\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0672 - accuracy: 0.9770\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0781 - accuracy: 0.9720\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0688 - accuracy: 0.9750\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0721 - accuracy: 0.9730\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0824 - accuracy: 0.9690\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0839 - accuracy: 0.9710\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0628 - accuracy: 0.9760\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.0633 - accuracy: 0.9790\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.0617 - accuracy: 0.9770\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0787 - accuracy: 0.9690\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0690 - accuracy: 0.9740\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0699 - accuracy: 0.9770\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0725 - accuracy: 0.9720\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0778 - accuracy: 0.9690\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0614 - accuracy: 0.9780\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0685 - accuracy: 0.9720\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0666 - accuracy: 0.9730\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0637 - accuracy: 0.9760\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0664 - accuracy: 0.9760\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0664 - accuracy: 0.9770\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0628 - accuracy: 0.9780\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0654 - accuracy: 0.9760\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0669 - accuracy: 0.9750\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0668 - accuracy: 0.9760\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0645 - accuracy: 0.9740\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0620 - accuracy: 0.9750\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0706 - accuracy: 0.9700\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0630 - accuracy: 0.9770\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0725 - accuracy: 0.9660\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0802 - accuracy: 0.9740\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0692 - accuracy: 0.9720\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0630 - accuracy: 0.9800\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0686 - accuracy: 0.9760\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0615 - accuracy: 0.9750\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0654 - accuracy: 0.9770\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0736 - accuracy: 0.9730\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0812 - accuracy: 0.9750\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0640 - accuracy: 0.9760\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0695 - accuracy: 0.9760\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.0638 - accuracy: 0.9730\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 1, input_shape=(2,), activation='sigmoid'))\n",
    "\"\"\"\n",
    "We need to specify what kind of optimizer we're going to use what kind of error function\n",
    "and tend to cross entropy and the metrics which is a function that you use to judge the \n",
    "performance of our model. So the optimizer will use ATOM were a lost function will equal \n",
    "some form of cross entropy which as you know is the the last function that will help determine the error.\n",
    "\"\"\"\n",
    "adam = Adam(lr = 0.1)\n",
    "\n",
    "\"\"\"\n",
    "Now since we're only dealing with two classes we'd expect a binary outcome of zeros \n",
    "and ones and thus we will be using binary across entropy by unary cross entropy. \n",
    "This calculates the cross entropy value for binary classification problems.\n",
    "(If we were dealing with three or more cost you would then use categorical across an \n",
    "attribute which calculates the cross entropy value for multiclass classification.)\n",
    "\n",
    "As for the metrics a metric is very similar to a loss function. However unlike the \n",
    "error function whose results as we saw are constantly back propagate it to minimize\n",
    "the error of our model. There is result from evaluating a metric are not used to train the \n",
    "model but simply to judge the performance at every park which is going to equal a list of functions.\n",
    "In our case we're interested in the accuracy which calculates the accuracy of how often the \n",
    "models predictions match the labels of our data.\n",
    "\"\"\"\n",
    "model.compile(adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\"\"\"\n",
    "Verbose is equal to one but that will do is simply display a progress bar of information \n",
    "relating to the performance of our model at each epoch.\n",
    "An epoch simply refers to whatever it iterates over the entire data set of points and \n",
    "labels to try and separate our data in discrete classes based on their assigned labels.\n",
    "So every time it iterates over the entire data set of points that is an epoch.\n",
    "However one IPAC is too big to feed to the computer all at once. So we need to divide it\n",
    "into several smaller batches. More specifically it would be a bot size 50.\n",
    "\"\"\"\n",
    "h = model.fit(x=X, y=y, verbose=1, batch_size=50, epochs=500, shuffle='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x62ff22860>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall the concept of gradient sets which updates the weights and biases of our network in the direction \n",
    "that decreases the air function the most. It's an iterative process which is why we need to pass the full \n",
    "dataset through our and your own that work multiple times to ensure an optimized results.\n",
    "\n",
    "In other words we need more than one epochs. If you simply specify one Pawk epoches equal to one that \n",
    "leads to the under fitting which doesn't capture the underlying trend of data as the number of epochs \n",
    "increase the more times it's able to update the weights of our neural network minimizing the error and \n",
    "thus producing the optimal results at the same time. You don't want to pass in too many epochs since \n",
    "that can lead to overfitting which is a modeling error that occurs when a function is too closely fit \n",
    "to a limited set of data points. This overfitting we're going to see a lot of examples of it.\n",
    "\n",
    "Once we deal with deeper neural networks now since we're dealing with a linear classification of relatively \n",
    "small complexity as opposed to a deeper neural network with a higher complexity which we will make use of \n",
    "later on in the course. One might think that overfitting isn't much of an issue although a linear classifier \n",
    "can absolutely be overfit if used without proper care.\n",
    "\n",
    "However if you have the right number of box it's going to model your data just fine. Unfortunately there isn't \n",
    "really the right answer as to how many epochs you should have. It really just depends on your dataset. So what\n",
    "will do is we'll just specify the possible to 500. It'll go through all of our data 500 times now 500 epochs \n",
    "is a bit much I'll admit. Realistically we're not going to need more than 10 epochs or so. But for the sake of \n",
    "demonstrating the training process and seeing a descriptive plot will extend the training process to go with 500 epochs.\n",
    "No don't actually get used to specifying too many POCs you'll see that this can get pretty bad once I demonstrate\n",
    "this in the convolutional neural network section as the model can start to overfit our training data and isn't able\n",
    "to generalize itself to new data. But regardless we'll cross that bridge when we get there.\n",
    "Now finally we're gonna set shuffle is equal to true this one should be new to you so as to shuffle our training\n",
    "before it Apoc as we use gradient descent to update the weights in the direction that decreases the area the most\n",
    "as it keeps minimizing the air it'll tend to get stuck in a local minimum of some sort rather than the \n",
    "absolute minimum. And our goal is to minimize the error the most. So what you want to do is ensure the \n",
    "absolute minimum of your last function to decrease the air as much as possible thereby maximizing the accuracy of \n",
    "our model. And so if you are dealing with static training data that's unchanged over all training iterations.\n",
    "\n",
    "Gradient descent algorithms will tend to get stuck in these local minima and the solution to this is to simply\n",
    "shuffle your training data. So what that does is it shuffles the rows in your data. And for each given iteration trains only a subset of them.\n",
    "This ensures that the subset of training it changes with every single iteration and thus if our algorithm \n",
    "worked to get stuck it would simply help and kind of bounce off the local minimum right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
